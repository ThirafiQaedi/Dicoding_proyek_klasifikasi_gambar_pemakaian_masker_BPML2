# -*- coding: utf-8 -*-
"""proyek_klasifikasi_gambar_pemakaian_masker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1idsdiS-EuxQ3nKXaLRSO0UC60bFMI-v-

#Proyek Klasifikasi Gambar: deteksi pemakaian masker

### Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
# Mengimpor libraries umum yang sering digunakan
import os, shutil
import zipfile
import random
from random import sample
import shutil
from shutil import copyfile
import pathlib
from pathlib import Path
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm as tq

# Mengimpor libraries untuk visualisasi
# %matplotlib inline
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.image import imread

# Mengimpor libraries untuk pemrosesan data gambar
import cv2
from PIL import Image
import skimage
from skimage import io
from skimage.transform import resize
from skimage.transform import rotate, AffineTransform, warp
from skimage import img_as_ubyte
from skimage.exposure import adjust_gamma
from skimage.util import random_noise

# Mengimpor libraries untuk pembuatan dan evaluasi model
import keras
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
!pip install tensorflow
!pip install tensorflowjs
import tensorflow as tf
from tensorflow.keras import Model, models , layers
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.layers import Input, InputLayer, Conv2D, SeparableConv2D, MaxPooling2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.applications.densenet import DenseNet121
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau

from PIL import Image

# Mengabaikan peringatan
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

#import library untuk kaggle
!pip install kaggle

#install tensorflowjs
!pip install tensorflowjs

# Import module yang disediakan google colab untuk kebutuhan upload file
from google.colab import files
files.upload()

"""### download data dari kaggle"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset
!unzip face-mask-12k-images-dataset.zip

"""### import data dan data spliting"""

train_path_dir = "/content/Face Mask Dataset/Train"
test_path_dir = "/content/Face Mask Dataset/Test"
validation_path_dir = "/content/Face Mask Dataset/Validation"


# function untuk check jumlah gambar per directori
def print_images_Total(dir):
    unique_sizes = set()
    total_images = 0
    for subdir in os.listdir(dir):
        subdir_path = os.path.join(dir, subdir)
        image_files = os.listdir(subdir_path)
        num_images = len(image_files)
        print(f"{subdir}: {num_images}")
        total_images += num_images

    print(f"\nTotal: {total_images}")

print_images_Total(train_path_dir)

print_images_Total(test_path_dir)

print_images_Total(validation_path_dir)

"""###Data Preprocessing"""

generated_train_data = ImageDataGenerator(
    rescale=1.0/255.0,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)
generated_val_test_data = ImageDataGenerator(rescale=1.0/255.0)

img_height, img_width = 224, 224
batch_size = 32

validat_data = generated_val_test_data.flow_from_directory(
    validation_path_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical'
)
test_data = generated_val_test_data.flow_from_directory(
    test_path_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)
train_data = generated_train_data.flow_from_directory(
    train_path_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical'
)

"""### Modeling"""

num_classes = len(train_data.class_indices)

model_classfy = models.Sequential()
model_classfy.add(Input(shape=(img_height, img_width, 3)))

# Layer 1
model_classfy.add(layers.Conv2D(32, (3, 3), activation='relu'))
model_classfy.add(layers.BatchNormalization())
model_classfy.add(layers.MaxPooling2D((2, 2)))

# Layer 2
model_classfy.add(layers.Conv2D(64, (3, 3), activation='relu'))
model_classfy.add(layers.BatchNormalization())
model_classfy.add(layers.MaxPooling2D((2, 2)))

# Layer 3
model_classfy.add(layers.Conv2D(128, (3, 3), activation='relu'))
model_classfy.add(layers.BatchNormalization())
model_classfy.add(layers.MaxPooling2D((2, 2)))

model_classfy.add(layers.Flatten())
model_classfy.add(layers.Dense(256, activation='relu'))
model_classfy.add(layers.Dropout(0.5))
model_classfy.add(layers.Dense(num_classes, activation='softmax'))

# Compile model
model_classfy.compile(optimizer='adam',
               loss='categorical_crossentropy',
               metrics=['accuracy'])

model_classfy.summary()

# Implementasi point Callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_LROnPlateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)

# Training Model
history = model_classfy.fit(
    train_data,
    validation_data=validat_data,
    epochs= 30,
    callbacks=[early_stopping, reduce_LROnPlateau]
)

"""### Evaluasi Model"""

# Evaluasi pada validation set
loss_val, acc_val = model_classfy.evaluate(validat_data)
print(f"Accuracy of Validation : {acc_val:.2%}")
print(f"Validation Loss: {loss_val:.4f}")

# Evaluasi pada testing set
loss_test, acc_test = model_classfy.evaluate(test_data)
print(f"Accuracy of Testing : {acc_test:.2%}")
print(f"Testing Loss: {loss_test:.4f}")

"""### # Visualisasi plot Akurasi dan Loss"""

# Plot Akurasi
plt.figure(figsize=(6, 5))

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.axhline(y=acc_val, color='r', linestyle='--', label='Validation Accuracy')
plt.axhline(y=acc_test, color='g', linestyle='--', label='Test Accuracy')
plt.legend()
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

plt.show()

# Plot Loss
plt.figure(figsize=(6, 5))

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.axhline(y=loss_val, color='y', linestyle='--', label='Validation Loss')
plt.axhline(y=loss_test, color='r', linestyle='--', label='Test Loss')
plt.legend()
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.show()

"""###Menyimpan Model"""

# SavedModel
save_path = 'SavedModel'
tf.saved_model.save(model_classfy, save_path)

# TF-Lite
convert_model_TLite = tf.lite.TFLiteConverter.from_keras_model(model_classfy)
tflite_model = convert_model_TLite.convert()

tflite_model_dir = 'tf_lite_model'
if not os.path.exists(tflite_model_dir):
    os.makedirs(tflite_model_dir)

tflite_model_path = os.path.join(tflite_model_dir, 'model.tflite')
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)

# Simpan label untuk model TF-Lite
class_labels = list(train_data.class_indices.keys())
with open("tf_lite_model/label.txt", "w") as f:
    for label in class_labels:
        f.write(label + "\n")

# TFJS
model_classfy.save('model_name.h5')
!tensorflowjs_converter --input_format=keras model_name.h5 tfjs_model

"""###(opsional) Inference (Menggunakan TF-Lite)"""

# Label kelas
class_labels = ["With Mask", "Without Mask"]
model_tflite_path='/content/tf_lite_model/model.tflite'

#membuat Function untuk predict
def _tflite_predict(image_path, model_path):
    # Load model
    interpreter = tf.lite.Interpreter(model_path=model_path)
    interpreter.allocate_tensors()

    # Ambil detail input & output
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # Ambil ukuran input model
    img_height, img_width = input_details[0]['shape'][1:3]

    # Load dan preprocess gambar
    img = Image.open(image_path).resize((img_height, img_width))
    img_array = np.array(img, dtype=np.float32) / 255.0
    img_array = np.expand_dims(img_array, axis=0)  # Tambahkan dimensi batch

    # Set input model
    interpreter.set_tensor(input_details[0]['index'], img_array)
    interpreter.invoke()

    # Ambil hasil prediksi
    predictions = interpreter.get_tensor(output_details[0]['index'])[0]

    # Dapatkan kelas dengan probabilitas tertinggi
    predicted_class = np.argmax(predictions)
    confidence = predictions[predicted_class] * 100

    # Tampilkan hasil prediksi
    print(f"\n=== HASIL PREDIKSI ===")
    for i, prob in enumerate(predictions):
        print(f"{class_labels[i]}: {prob:.4f}")

    print(f"\nKelas Terpilih: {class_labels[predicted_class]} ({confidence:.2f}%)")

    return class_labels[predicted_class], confidence

"""##### case 1 with mask"""

# Path gambar yang akan diuji
image_path_case1 = "/content/Face Mask Dataset/Test/WithMask/1612.png"

# Jalankan prediksi
predicted_label, confidence = _tflite_predict(image_path_case1,model_tflite_path)

"""##### case 2 without mask"""

# Path gambar yang akan diuji
image_path_case2 = "/content/Face Mask Dataset/Test/WithoutMask/1216.png"

# Jalankan prediksi
predicted_label, confidence = _tflite_predict(image_path_case2,model_tflite_path)

"""###DOnwload ZIP model dan requirement"""

shutil.make_archive('/content/SavedModel', 'zip', '/content/SavedModel')

shutil.make_archive('/content/tf_lite_model', 'zip', '/content/tf_lite_model')

shutil.make_archive('/content/tfjs_model', 'zip', '/content/tfjs_model')

!pip freeze requirements.txt